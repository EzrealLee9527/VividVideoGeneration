dwpose_only_face: true
froce_text_embedding_zero: true

image_finetune: false
output_dir: "outputs"
pretrained_model_path: '/data/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/1d0c4ebf6ff58a5caecab40fa1406526bca4b5b9'
pretrained_vae_path: "/data/models/pretrained_models/sd-vae-ft-mse"
image_encoder_path: "/data/work/IP-Adapter/IP-Adapter/models/image_encoder"
ip_ckpt: "/data/work/IP-Adapter/IP-Adapter/models/ip-adapter-full-face_sd15.bin"
# image_encoder_path: ""
# ip_ckpt: ""
pretrained_appearance_encoder_path: "/data/models/pretrained_models/MagicAnimate/appearance_encoder"
pretrained_controlnet_path: "/data/models/pretrained_models/MagicAnimate/densepose_controlnet"
motion_module: "/data/models/pretrained_models/MagicAnimate/temporal_attention/temporal_attention.ckpt"
inference_config: "configs/inference/magic_inference.yaml"
pretrained_unet_path: ""

# stage1 trained
appearance_controlnet_motion_checkpoint_path: "/data/work/VividVideoGeneration/outputs/train_stage1_video_celebv_nocenterface_cfg_train_magic_ipadapter_fuseall-2024-02-05T14-13-48/checkpoints/checkpoint-steps26000.ckpt"
# appearance_controlnet_motion_checkpoint_path: "/data/work/animate_based_ap_stage2/outputs/train_stage1_w_imageencoder_celebv-2023-12-31T00-01-25/checkpoints/checkpoint-steps2500.ckpt"

dwpose:
  det_config: '/data/models/controlnet_aux/src/controlnet_aux/dwpose/yolox_config/yolox_l_8xb8-300e_coco.py'
  det_ckpt: '/data/models/controlnet_aux/yolox_l_8x8_300e_coco_20211126_140236-d3bd2b23.pth'
  pose_config: '/data/models/controlnet_aux/src/controlnet_aux/dwpose/dwpose_config/dwpose-l_384x288.py'
  pose_ckpt: '/data/models/controlnet_aux/dw-ll_ucoco_384.pth'

unet_additional_kwargs:
  unet_use_cross_frame_attention: false
  unet_use_temporal_attention: false
  use_motion_module: true # stage1
  motion_module_resolutions:
  - 1
  - 2
  - 4
  - 8
  motion_module_mid_block: false
  motion_module_decoder_only: false
  motion_module_type: Vanilla
  motion_module_kwargs:
    num_attention_heads: 8
    num_transformer_block: 1
    attention_block_types:
    - Temporal_Self
    - Temporal_Self
    temporal_position_encoding: true
    temporal_position_encoding_max_len: 24
    temporal_attention_dim_div: 1

  # Addition for image embeddings
  use_image_condition            : true


noise_scheduler_kwargs:
  num_train_timesteps: 1000
  beta_start:          0.00085
  beta_end:            0.012
  beta_schedule:       "scaled_linear" # 这部分animatediff和magic不一样？
  steps_offset:        1
  clip_sample:         false

data_module:          'animatediff.data.dataset_wds'
data_class:           'S3VideosIterableDataset'
train_data:
  data_dirs:          ['s3://ljj/Datasets/Videos/processed/CelebV_webdataset_20231211',
                      # 's3://ljj/Datasets/Videos/processed/hdvila100m_20231216',
                      # 's3://ljj/Datasets/Videos/processed/pexels_20231217',
                      # 's3://ljj/Datasets/Videos/processed/xiaohongshu_webdataset_20231212',
                      ]
  resolution:         [512, 512]
  frame_stride:       1
  video_length:       8
  shuffle:            true
  resampled:          true
  dataset_length:     1000000
  endpoint_url:       "http://oss.i.shaipower.com:80"

validation_data:
  dataset:
    data_dirs:          [
                        's3://ljj/Datasets/Videos/processed/pexels_20231217',
                        ]
    resolution:         [512, 512]
    frame_stride:       2
    video_length:       8
    shuffle:            true
    resampled:          true
    dataset_length:     1000000
    endpoint_url:       "http://oss.i.shaipower.com:80"
    is_det_face:        true
  prompt_videos:
    - "/data/work/animate_based_ap/data/celebv/10876-2-7eMjYXRcm-0_12_0.mp4"
    - "/data/work/animate_based_ap/data/celebv/10894-8-7ebsTST4bSw_1_0.mp4"
    - ""
  num_inference_steps: 25
  guidance_scale: 
    - 7.5
    - 4
    - 2
    - 1
  val_video_length: 8
  sample_size: [512, 512]
  frame_stride:       1
context:
  context_frames: 8
  context_stride: 1
  context_overlap: 0

# stage1 TODO: image_encoder部分？
trainable_modules:
  # - "appearance_encoder"
  # - "controlnet"
  # - "image_proj_model"
  - "motion_module"


unet_checkpoint_path: ""

learning_rate:    1.e-5
train_batch_size: 1
num_workers: 1

max_train_epoch:      100
max_train_steps:      -1
checkpointing_epochs: -1
checkpointing_steps:  2000

validation_steps:       200
validation_steps_tuple: [2, 25, 50, 75, 100]

global_seed: 42
mixed_precision_training: true
enable_xformers_memory_efficient_attention: True

is_debug: False
